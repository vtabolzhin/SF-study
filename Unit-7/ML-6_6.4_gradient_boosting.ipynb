{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7c5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdbf108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crl.tot</th>\n",
       "      <th>dollar</th>\n",
       "      <th>bang</th>\n",
       "      <th>money</th>\n",
       "      <th>n000</th>\n",
       "      <th>make</th>\n",
       "      <th>yesno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>4597</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>4598</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>4599</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>4600</td>\n",
       "      <td>78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>4601</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  crl.tot  dollar   bang  money  n000  make yesno\n",
       "4596        4597       88     0.0  0.000    0.0   0.0  0.31     n\n",
       "4597        4598       14     0.0  0.353    0.0   0.0  0.00     n\n",
       "4598        4599      118     0.0  0.000    0.0   0.0  0.30     n\n",
       "4599        4600       78     0.0  0.000    0.0   0.0  0.96     n\n",
       "4600        4601       40     0.0  0.125    0.0   0.0  0.00     n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/DAAG/spam7.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec25fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spam'] = df['yesno'].apply(lambda x: 1 if x=='y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f316fa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yesno  spam\n",
       "n      0       2788\n",
       "y      1       1813\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['yesno','spam']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7607119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([df.columns[0],'yesno'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d236964b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crl.tot</th>\n",
       "      <th>dollar</th>\n",
       "      <th>bang</th>\n",
       "      <th>money</th>\n",
       "      <th>n000</th>\n",
       "      <th>make</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1028</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2259</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>78</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      crl.tot  dollar   bang  money  n000  make  spam\n",
       "0         278   0.000  0.778   0.00  0.00  0.00     1\n",
       "1        1028   0.180  0.372   0.43  0.43  0.21     1\n",
       "2        2259   0.184  0.276   0.06  1.16  0.06     1\n",
       "3         191   0.000  0.137   0.00  0.00  0.00     1\n",
       "4         191   0.000  0.135   0.00  0.00  0.00     1\n",
       "...       ...     ...    ...    ...   ...   ...   ...\n",
       "4596       88   0.000  0.000   0.00  0.00  0.31     0\n",
       "4597       14   0.000  0.353   0.00  0.00  0.00     0\n",
       "4598      118   0.000  0.000   0.00  0.00  0.30     0\n",
       "4599       78   0.000  0.000   0.00  0.00  0.96     0\n",
       "4600       40   0.000  0.125   0.00  0.00  0.00     0\n",
       "\n",
       "[4601 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2bf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('spam', axis=1)\n",
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b098e8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.000\n",
       "1       185.040\n",
       "2       415.656\n",
       "3         0.000\n",
       "4         0.000\n",
       "         ...   \n",
       "4596      0.000\n",
       "4597      0.000\n",
       "4598      0.000\n",
       "4599      0.000\n",
       "4600      0.000\n",
       "Length: 4601, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.columns[[0,1]]].prod(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e71785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crl.tot', 'dollar'),\n",
       " ('crl.tot', 'bang'),\n",
       " ('crl.tot', 'money'),\n",
       " ('crl.tot', 'n000'),\n",
       " ('crl.tot', 'make'),\n",
       " ('dollar', 'bang'),\n",
       " ('dollar', 'money'),\n",
       " ('dollar', 'n000'),\n",
       " ('dollar', 'make'),\n",
       " ('bang', 'money'),\n",
       " ('bang', 'n000'),\n",
       " ('bang', 'make'),\n",
       " ('money', 'n000'),\n",
       " ('money', 'make'),\n",
       " ('n000', 'make')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "feature_combinations = list(combinations(X.columns, 2))\n",
    "feature_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43892d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.000\n",
       "1       185.040\n",
       "2       415.656\n",
       "3         0.000\n",
       "4         0.000\n",
       "         ...   \n",
       "4596      0.000\n",
       "4597      0.000\n",
       "4598      0.000\n",
       "4599      0.000\n",
       "4600      0.000\n",
       "Length: 4601, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[list(feature_combinations[0])].prod(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd9cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crl.tot_dollar'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(feature_combinations[0])[2:-2].replace(\"', '\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6491904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in feature_combinations:\n",
    "    feature_name = str(c)[2:-2].replace(\"', '\",\"_\")\n",
    "    X[feature_name] = X[list(c)].prod(axis=1)\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# pf = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "# poly_data = pf.fit_transform(X)\n",
    "# poly_cols = pf.get_feature_names(X.columns)\n",
    "# X = pd.DataFrame(poly_data, columns=poly_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd22a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crl.tot</th>\n",
       "      <th>dollar</th>\n",
       "      <th>bang</th>\n",
       "      <th>money</th>\n",
       "      <th>n000</th>\n",
       "      <th>make</th>\n",
       "      <th>crl.tot_dollar</th>\n",
       "      <th>crl.tot_bang</th>\n",
       "      <th>crl.tot_money</th>\n",
       "      <th>crl.tot_n000</th>\n",
       "      <th>...</th>\n",
       "      <th>dollar_bang</th>\n",
       "      <th>dollar_money</th>\n",
       "      <th>dollar_n000</th>\n",
       "      <th>dollar_make</th>\n",
       "      <th>bang_money</th>\n",
       "      <th>bang_n000</th>\n",
       "      <th>bang_make</th>\n",
       "      <th>money_n000</th>\n",
       "      <th>money_make</th>\n",
       "      <th>n000_make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>216.284</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1028</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>185.040</td>\n",
       "      <td>382.416</td>\n",
       "      <td>442.04</td>\n",
       "      <td>442.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.07740</td>\n",
       "      <td>0.07740</td>\n",
       "      <td>0.03780</td>\n",
       "      <td>0.15996</td>\n",
       "      <td>0.15996</td>\n",
       "      <td>0.07812</td>\n",
       "      <td>0.1849</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2259</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>415.656</td>\n",
       "      <td>623.484</td>\n",
       "      <td>135.54</td>\n",
       "      <td>2620.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050784</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.21344</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.01656</td>\n",
       "      <td>0.32016</td>\n",
       "      <td>0.01656</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.167</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.785</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>78</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      crl.tot  dollar   bang  money  n000  make  crl.tot_dollar  crl.tot_bang  \\\n",
       "0         278   0.000  0.778   0.00  0.00  0.00           0.000       216.284   \n",
       "1        1028   0.180  0.372   0.43  0.43  0.21         185.040       382.416   \n",
       "2        2259   0.184  0.276   0.06  1.16  0.06         415.656       623.484   \n",
       "3         191   0.000  0.137   0.00  0.00  0.00           0.000        26.167   \n",
       "4         191   0.000  0.135   0.00  0.00  0.00           0.000        25.785   \n",
       "...       ...     ...    ...    ...   ...   ...             ...           ...   \n",
       "4596       88   0.000  0.000   0.00  0.00  0.31           0.000         0.000   \n",
       "4597       14   0.000  0.353   0.00  0.00  0.00           0.000         4.942   \n",
       "4598      118   0.000  0.000   0.00  0.00  0.30           0.000         0.000   \n",
       "4599       78   0.000  0.000   0.00  0.00  0.96           0.000         0.000   \n",
       "4600       40   0.000  0.125   0.00  0.00  0.00           0.000         5.000   \n",
       "\n",
       "      crl.tot_money  crl.tot_n000  ...  dollar_bang  dollar_money  \\\n",
       "0              0.00          0.00  ...     0.000000       0.00000   \n",
       "1            442.04        442.04  ...     0.066960       0.07740   \n",
       "2            135.54       2620.44  ...     0.050784       0.01104   \n",
       "3              0.00          0.00  ...     0.000000       0.00000   \n",
       "4              0.00          0.00  ...     0.000000       0.00000   \n",
       "...             ...           ...  ...          ...           ...   \n",
       "4596           0.00          0.00  ...     0.000000       0.00000   \n",
       "4597           0.00          0.00  ...     0.000000       0.00000   \n",
       "4598           0.00          0.00  ...     0.000000       0.00000   \n",
       "4599           0.00          0.00  ...     0.000000       0.00000   \n",
       "4600           0.00          0.00  ...     0.000000       0.00000   \n",
       "\n",
       "      dollar_n000  dollar_make  bang_money  bang_n000  bang_make  money_n000  \\\n",
       "0         0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "1         0.07740      0.03780     0.15996    0.15996    0.07812      0.1849   \n",
       "2         0.21344      0.01104     0.01656    0.32016    0.01656      0.0696   \n",
       "3         0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "4         0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "...           ...          ...         ...        ...        ...         ...   \n",
       "4596      0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "4597      0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "4598      0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "4599      0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "4600      0.00000      0.00000     0.00000    0.00000    0.00000      0.0000   \n",
       "\n",
       "      money_make  n000_make  \n",
       "0         0.0000     0.0000  \n",
       "1         0.0903     0.0903  \n",
       "2         0.0036     0.0696  \n",
       "3         0.0000     0.0000  \n",
       "4         0.0000     0.0000  \n",
       "...          ...        ...  \n",
       "4596      0.0000     0.0000  \n",
       "4597      0.0000     0.0000  \n",
       "4598      0.0000     0.0000  \n",
       "4599      0.0000     0.0000  \n",
       "4600      0.0000     0.0000  \n",
       "\n",
       "[4601 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044dce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50202aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653637350705755"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f04e33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "money_make        0.000000\n",
       "money_n000        0.000027\n",
       "n000_make         0.000661\n",
       "make              0.001166\n",
       "bang_n000         0.001176\n",
       "crl.tot_n000      0.001366\n",
       "dollar_make       0.001694\n",
       "bang_make         0.001965\n",
       "dollar_n000       0.003422\n",
       "money             0.006090\n",
       "bang_money        0.006469\n",
       "crl.tot_make      0.006539\n",
       "dollar_money      0.007222\n",
       "crl.tot_dollar    0.008679\n",
       "n000              0.024777\n",
       "crl.tot           0.029674\n",
       "crl.tot_money     0.040245\n",
       "bang              0.042614\n",
       "dollar_bang       0.060567\n",
       "dollar            0.140770\n",
       "crl.tot_bang      0.614877\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.Series(clf.feature_importances_, index = X.columns).sort_values(ascending=True)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0265952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 425
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(importances.index, width = importances);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6bcd993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'n_estimators': [100, 250, 500, 750, 1000, 1250, 1500,\n",
       "                                          1750]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'learning_rate':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "              'n_estimators':[100, 250, 500, 750, 1000, 1250, 1500, 1750]}\n",
    "\n",
    "clf = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring = 'accuracy',\n",
    "                   n_jobs=-1,\n",
    "                   cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7d96b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8836956521739131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46cf4bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'n_estimators': 1250}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e1d76fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.749594</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 100}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.330441</td>\n",
       "      <td>0.119158</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 250}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.235623</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 500}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.479896</td>\n",
       "      <td>0.171974</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 750}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744316</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.011569</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 1000}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.854149</td>\n",
       "      <td>0.055167</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 1250}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.910325</td>\n",
       "      <td>0.062416</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 1500}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.040503</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 1e-05, 'n_estimators': 1750}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.457775</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 100}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.150723</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 250}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.293667</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 500}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.511611</td>\n",
       "      <td>0.083248</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 750}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.698039</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 1000}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.715918</td>\n",
       "      <td>0.037394</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 1250}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.878609</td>\n",
       "      <td>0.047869</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 1500}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.132259</td>\n",
       "      <td>0.122226</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 0.0001, 'n_estimators': 1750}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.487695</td>\n",
       "      <td>0.036191</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 100}</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.612772</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.613315</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.198593</td>\n",
       "      <td>0.060926</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 250}</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.748641</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.743207</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.758696</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.333760</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 500}</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.870924</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.863043</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.553897</td>\n",
       "      <td>0.049472</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 750}</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.860054</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.811445</td>\n",
       "      <td>0.372763</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 1000}</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.202769</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 1250}</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.876087</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.415856</td>\n",
       "      <td>0.061978</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 1500}</td>\n",
       "      <td>0.883152</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.877174</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.406106</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 0.001, 'n_estimators': 1750}</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.878533</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.428022</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 100}</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.870924</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.875272</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.059126</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 250}</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.860054</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.879348</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.175458</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 500}</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.889946</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.879348</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.183274</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.01</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 750}</td>\n",
       "      <td>0.889946</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.882065</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.367753</td>\n",
       "      <td>0.091593</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 1000}</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.889946</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.882337</td>\n",
       "      <td>0.013494</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.720412</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 1250}</td>\n",
       "      <td>0.895380</td>\n",
       "      <td>0.860054</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.889946</td>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.883696</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.865201</td>\n",
       "      <td>0.022823</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 1500}</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.883696</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.640292</td>\n",
       "      <td>0.121744</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 1750}</td>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.883696</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.428009</td>\n",
       "      <td>0.012922</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.861413</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.882609</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.074466</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 250}</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.881522</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.150107</td>\n",
       "      <td>0.011951</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 500}</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.861413</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.879620</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.258265</td>\n",
       "      <td>0.072344</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 750}</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.875272</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.391047</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1000}</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.887228</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.416091</td>\n",
       "      <td>0.083399</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1250}</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.873098</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6.801086</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1500}</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.870380</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.982775</td>\n",
       "      <td>0.069945</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1750}</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.845109</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.870924</td>\n",
       "      <td>0.868478</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.454451</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.849185</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.881793</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.149536</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 250}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.870109</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.397475</td>\n",
       "      <td>0.083988</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 500}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.866304</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.499549</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 750}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.839674</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.864946</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.539821</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1000}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.835598</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.016099</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.768355</td>\n",
       "      <td>0.123971</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>1</td>\n",
       "      <td>1250</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1250}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.863315</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.028993</td>\n",
       "      <td>0.149451</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1500}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.868207</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.862228</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8.060386</td>\n",
       "      <td>0.146015</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>1</td>\n",
       "      <td>1750</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1750}</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.839674</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.861685</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.749594      0.088512         0.003192        0.000399   \n",
       "1        1.330441      0.119158         0.004588        0.000489   \n",
       "2        2.235623      0.011675         0.006782        0.000747   \n",
       "3        3.479896      0.171974         0.008377        0.000489   \n",
       "4        4.744316      0.099976         0.011569        0.001017   \n",
       "5        5.854149      0.055167         0.013165        0.000747   \n",
       "6        6.910325      0.062416         0.016556        0.003764   \n",
       "7        8.040503      0.049050         0.017952        0.001262   \n",
       "8        0.457775      0.006401         0.003391        0.000488   \n",
       "9        1.150723      0.011448         0.004388        0.000488   \n",
       "10       2.293667      0.028282         0.007181        0.000746   \n",
       "11       3.511611      0.083248         0.009375        0.001018   \n",
       "12       4.698039      0.052811         0.011769        0.000399   \n",
       "13       5.715918      0.037394         0.014561        0.000798   \n",
       "14       6.878609      0.047869         0.016556        0.000489   \n",
       "15       8.132259      0.122226         0.019349        0.001197   \n",
       "16       0.487695      0.036191         0.003192        0.000977   \n",
       "17       1.198593      0.060926         0.005386        0.000488   \n",
       "18       2.333760      0.053478         0.007380        0.000798   \n",
       "19       3.553897      0.049472         0.010173        0.000746   \n",
       "20       4.811445      0.372763         0.012566        0.000798   \n",
       "21       6.202769      0.546312         0.012366        0.006188   \n",
       "22       6.415856      0.061978         0.015622        0.000001   \n",
       "23       7.406106      0.033917         0.021556        0.007286   \n",
       "24       0.428022      0.012499         0.003124        0.006248   \n",
       "25       1.059126      0.006249         0.003124        0.006248   \n",
       "26       2.175458      0.021274         0.005916        0.005770   \n",
       "27       3.183274      0.030878         0.009373        0.007653   \n",
       "28       4.367753      0.091593         0.012233        0.002767   \n",
       "29       5.720412      0.036964         0.012698        0.001591   \n",
       "30       6.865201      0.022823         0.014029        0.001303   \n",
       "31       7.640292      0.121744         0.015158        0.000651   \n",
       "32       0.428009      0.012922         0.003723        0.006062   \n",
       "33       1.074466      0.009579         0.003124        0.006248   \n",
       "34       2.150107      0.011951         0.007503        0.007014   \n",
       "35       3.258265      0.072344         0.004720        0.006266   \n",
       "36       4.391047      0.013475         0.008044        0.007002   \n",
       "37       5.416091      0.083399         0.007313        0.006268   \n",
       "38       6.801086      0.052604         0.012367        0.000489   \n",
       "39       7.982775      0.069945         0.015093        0.000266   \n",
       "40       0.454451      0.011627         0.002393        0.001353   \n",
       "41       1.149536      0.030319         0.003989        0.000001   \n",
       "42       2.397475      0.083988         0.005386        0.000488   \n",
       "43       3.499549      0.045288         0.007513        0.004960   \n",
       "44       4.539821      0.056953         0.010505        0.002588   \n",
       "45       5.768355      0.123971         0.011302        0.002530   \n",
       "46       7.028993      0.149451         0.013244        0.001760   \n",
       "47       8.060386      0.146015         0.016356        0.004618   \n",
       "\n",
       "   param_learning_rate param_n_estimators  \\\n",
       "0              0.00001                100   \n",
       "1              0.00001                250   \n",
       "2              0.00001                500   \n",
       "3              0.00001                750   \n",
       "4              0.00001               1000   \n",
       "5              0.00001               1250   \n",
       "6              0.00001               1500   \n",
       "7              0.00001               1750   \n",
       "8               0.0001                100   \n",
       "9               0.0001                250   \n",
       "10              0.0001                500   \n",
       "11              0.0001                750   \n",
       "12              0.0001               1000   \n",
       "13              0.0001               1250   \n",
       "14              0.0001               1500   \n",
       "15              0.0001               1750   \n",
       "16               0.001                100   \n",
       "17               0.001                250   \n",
       "18               0.001                500   \n",
       "19               0.001                750   \n",
       "20               0.001               1000   \n",
       "21               0.001               1250   \n",
       "22               0.001               1500   \n",
       "23               0.001               1750   \n",
       "24                0.01                100   \n",
       "25                0.01                250   \n",
       "26                0.01                500   \n",
       "27                0.01                750   \n",
       "28                0.01               1000   \n",
       "29                0.01               1250   \n",
       "30                0.01               1500   \n",
       "31                0.01               1750   \n",
       "32                 0.1                100   \n",
       "33                 0.1                250   \n",
       "34                 0.1                500   \n",
       "35                 0.1                750   \n",
       "36                 0.1               1000   \n",
       "37                 0.1               1250   \n",
       "38                 0.1               1500   \n",
       "39                 0.1               1750   \n",
       "40                   1                100   \n",
       "41                   1                250   \n",
       "42                   1                500   \n",
       "43                   1                750   \n",
       "44                   1               1000   \n",
       "45                   1               1250   \n",
       "46                   1               1500   \n",
       "47                   1               1750   \n",
       "\n",
       "                                             params  split0_test_score  \\\n",
       "0     {'learning_rate': 1e-05, 'n_estimators': 100}           0.612772   \n",
       "1     {'learning_rate': 1e-05, 'n_estimators': 250}           0.612772   \n",
       "2     {'learning_rate': 1e-05, 'n_estimators': 500}           0.612772   \n",
       "3     {'learning_rate': 1e-05, 'n_estimators': 750}           0.612772   \n",
       "4    {'learning_rate': 1e-05, 'n_estimators': 1000}           0.612772   \n",
       "5    {'learning_rate': 1e-05, 'n_estimators': 1250}           0.612772   \n",
       "6    {'learning_rate': 1e-05, 'n_estimators': 1500}           0.612772   \n",
       "7    {'learning_rate': 1e-05, 'n_estimators': 1750}           0.612772   \n",
       "8    {'learning_rate': 0.0001, 'n_estimators': 100}           0.612772   \n",
       "9    {'learning_rate': 0.0001, 'n_estimators': 250}           0.612772   \n",
       "10   {'learning_rate': 0.0001, 'n_estimators': 500}           0.612772   \n",
       "11   {'learning_rate': 0.0001, 'n_estimators': 750}           0.612772   \n",
       "12  {'learning_rate': 0.0001, 'n_estimators': 1000}           0.612772   \n",
       "13  {'learning_rate': 0.0001, 'n_estimators': 1250}           0.612772   \n",
       "14  {'learning_rate': 0.0001, 'n_estimators': 1500}           0.612772   \n",
       "15  {'learning_rate': 0.0001, 'n_estimators': 1750}           0.612772   \n",
       "16    {'learning_rate': 0.001, 'n_estimators': 100}           0.612772   \n",
       "17    {'learning_rate': 0.001, 'n_estimators': 250}           0.770380   \n",
       "18    {'learning_rate': 0.001, 'n_estimators': 500}           0.868207   \n",
       "19    {'learning_rate': 0.001, 'n_estimators': 750}           0.876359   \n",
       "20   {'learning_rate': 0.001, 'n_estimators': 1000}           0.887228   \n",
       "21   {'learning_rate': 0.001, 'n_estimators': 1250}           0.884511   \n",
       "22   {'learning_rate': 0.001, 'n_estimators': 1500}           0.883152   \n",
       "23   {'learning_rate': 0.001, 'n_estimators': 1750}           0.885870   \n",
       "24     {'learning_rate': 0.01, 'n_estimators': 100}           0.887228   \n",
       "25     {'learning_rate': 0.01, 'n_estimators': 250}           0.887228   \n",
       "26     {'learning_rate': 0.01, 'n_estimators': 500}           0.888587   \n",
       "27     {'learning_rate': 0.01, 'n_estimators': 750}           0.889946   \n",
       "28    {'learning_rate': 0.01, 'n_estimators': 1000}           0.891304   \n",
       "29    {'learning_rate': 0.01, 'n_estimators': 1250}           0.895380   \n",
       "30    {'learning_rate': 0.01, 'n_estimators': 1500}           0.894022   \n",
       "31    {'learning_rate': 0.01, 'n_estimators': 1750}           0.892663   \n",
       "32      {'learning_rate': 0.1, 'n_estimators': 100}           0.891304   \n",
       "33      {'learning_rate': 0.1, 'n_estimators': 250}           0.888587   \n",
       "34      {'learning_rate': 0.1, 'n_estimators': 500}           0.896739   \n",
       "35      {'learning_rate': 0.1, 'n_estimators': 750}           0.887228   \n",
       "36     {'learning_rate': 0.1, 'n_estimators': 1000}           0.884511   \n",
       "37     {'learning_rate': 0.1, 'n_estimators': 1250}           0.881793   \n",
       "38     {'learning_rate': 0.1, 'n_estimators': 1500}           0.876359   \n",
       "39     {'learning_rate': 0.1, 'n_estimators': 1750}           0.876359   \n",
       "40        {'learning_rate': 1, 'n_estimators': 100}           0.869565   \n",
       "41        {'learning_rate': 1, 'n_estimators': 250}           0.877717   \n",
       "42        {'learning_rate': 1, 'n_estimators': 500}           0.877717   \n",
       "43        {'learning_rate': 1, 'n_estimators': 750}           0.877717   \n",
       "44       {'learning_rate': 1, 'n_estimators': 1000}           0.877717   \n",
       "45       {'learning_rate': 1, 'n_estimators': 1250}           0.877717   \n",
       "46       {'learning_rate': 1, 'n_estimators': 1500}           0.877717   \n",
       "47       {'learning_rate': 1, 'n_estimators': 1750}           0.877717   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.612772           0.612772           0.614130   \n",
       "1            0.612772           0.612772           0.614130   \n",
       "2            0.612772           0.612772           0.614130   \n",
       "3            0.612772           0.612772           0.614130   \n",
       "4            0.612772           0.612772           0.614130   \n",
       "5            0.612772           0.612772           0.614130   \n",
       "6            0.612772           0.612772           0.614130   \n",
       "7            0.612772           0.612772           0.614130   \n",
       "8            0.612772           0.612772           0.614130   \n",
       "9            0.612772           0.612772           0.614130   \n",
       "10           0.612772           0.612772           0.614130   \n",
       "11           0.612772           0.612772           0.614130   \n",
       "12           0.612772           0.612772           0.614130   \n",
       "13           0.612772           0.612772           0.614130   \n",
       "14           0.612772           0.612772           0.614130   \n",
       "15           0.612772           0.612772           0.614130   \n",
       "16           0.612772           0.612772           0.614130   \n",
       "17           0.748641           0.770380           0.743207   \n",
       "18           0.850543           0.858696           0.870924   \n",
       "19           0.854620           0.860054           0.873641   \n",
       "20           0.855978           0.869565           0.880435   \n",
       "21           0.855978           0.873641           0.884511   \n",
       "22           0.858696           0.873641           0.885870   \n",
       "23           0.858696           0.876359           0.884511   \n",
       "24           0.855978           0.870924           0.880435   \n",
       "25           0.860054           0.875000           0.885870   \n",
       "26           0.855978           0.873641           0.889946   \n",
       "27           0.858696           0.876359           0.891304   \n",
       "28           0.857337           0.879076           0.889946   \n",
       "29           0.860054           0.880435           0.889946   \n",
       "30           0.864130           0.879076           0.887228   \n",
       "31           0.866848           0.880435           0.884511   \n",
       "32           0.861413           0.879076           0.888587   \n",
       "33           0.866848           0.873641           0.881793   \n",
       "34           0.861413           0.869565           0.879076   \n",
       "35           0.858696           0.868207           0.880435   \n",
       "36           0.855978           0.869565           0.887228   \n",
       "37           0.855978           0.872283           0.881793   \n",
       "38           0.850543           0.873641           0.879076   \n",
       "39           0.845109           0.869565           0.880435   \n",
       "40           0.849185           0.869565           0.881793   \n",
       "41           0.847826           0.876359           0.884511   \n",
       "42           0.843750           0.873641           0.879076   \n",
       "43           0.839674           0.873641           0.880435   \n",
       "44           0.835598           0.872283           0.877717   \n",
       "45           0.836957           0.872283           0.875000   \n",
       "46           0.836957           0.868207           0.873641   \n",
       "47           0.839674           0.866848           0.866848   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.614130         0.613315        0.000666               32  \n",
       "1            0.614130         0.613315        0.000666               32  \n",
       "2            0.614130         0.613315        0.000666               32  \n",
       "3            0.614130         0.613315        0.000666               32  \n",
       "4            0.614130         0.613315        0.000666               32  \n",
       "5            0.614130         0.613315        0.000666               32  \n",
       "6            0.614130         0.613315        0.000666               32  \n",
       "7            0.614130         0.613315        0.000666               32  \n",
       "8            0.614130         0.613315        0.000666               32  \n",
       "9            0.614130         0.613315        0.000666               32  \n",
       "10           0.614130         0.613315        0.000666               32  \n",
       "11           0.614130         0.613315        0.000666               32  \n",
       "12           0.614130         0.613315        0.000666               32  \n",
       "13           0.614130         0.613315        0.000666               32  \n",
       "14           0.614130         0.613315        0.000666               32  \n",
       "15           0.614130         0.613315        0.000666               32  \n",
       "16           0.614130         0.613315        0.000666               32  \n",
       "17           0.760870         0.758696        0.011125               31  \n",
       "18           0.866848         0.863043        0.007462               28  \n",
       "19           0.879076         0.868750        0.009630               22  \n",
       "20           0.881793         0.875000        0.011105               16  \n",
       "21           0.881793         0.876087        0.010815               13  \n",
       "22           0.884511         0.877174        0.010189               12  \n",
       "23           0.887228         0.878533        0.010615               11  \n",
       "24           0.881793         0.875272        0.010984               14  \n",
       "25           0.888587         0.879348        0.010781                9  \n",
       "26           0.888587         0.879348        0.013128               10  \n",
       "27           0.894022         0.882065        0.013184                6  \n",
       "28           0.894022         0.882337        0.013494                5  \n",
       "29           0.892663         0.883696        0.012850                1  \n",
       "30           0.894022         0.883696        0.011224                1  \n",
       "31           0.894022         0.883696        0.009820                1  \n",
       "32           0.892663         0.882609        0.011612                4  \n",
       "33           0.896739         0.881522        0.010573                7  \n",
       "34           0.891304         0.879620        0.013134                8  \n",
       "35           0.881793         0.875272        0.010362               14  \n",
       "36           0.877717         0.875000        0.011303               16  \n",
       "37           0.873641         0.873098        0.009437               18  \n",
       "38           0.872283         0.870380        0.010189               19  \n",
       "39           0.870924         0.868478        0.012316               23  \n",
       "40           0.876359         0.869293        0.011051               21  \n",
       "41           0.864130         0.870109        0.012935               20  \n",
       "42           0.857337         0.866304        0.013684               24  \n",
       "43           0.853261         0.864946        0.015836               25  \n",
       "44           0.857337         0.864130        0.016099               26  \n",
       "45           0.854620         0.863315        0.015458               27  \n",
       "46           0.854620         0.862228        0.014849               29  \n",
       "47           0.857337         0.861685        0.012757               30  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1734909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                  n_estimators=1250,\n",
       "                                                  random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(5,16)}\n",
    "\n",
    "clf = GridSearchCV(estimator=GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                        n_estimators=1250,                                                        \n",
    "                                                        random_state=42),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring = 'accuracy',\n",
    "                   n_jobs=-1,\n",
    "                   cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d0348fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15622648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8853260869565217"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f18c0a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17713540534666378"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(y)\n",
    "sample_weight = np.ones(N) / N\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2)\n",
    "estimator.fit(X, y, sample_weight=sample_weight)\n",
    "y_predict = estimator.predict(X)\n",
    "\n",
    "incorrect = (y_predict != y)\n",
    "\n",
    "(sample_weight*incorrect).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3a223d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8228645946533363\n"
     ]
    }
   ],
   "source": [
    "def AdaBoost_scratch(X,y, M=10, learning_rate = 1):\n",
    "    # инициалиазция служебных переменных\n",
    "    N = len(y)\n",
    "    estimator_list, y_predict_list, estimator_error_list,\\\n",
    "    estimator_weight_list, sample_weight_list = [], [], [], [], []\n",
    "\n",
    "    # инициализация весов\n",
    "    sample_weight = np.ones(N) / N\n",
    "    sample_weight_list.append(sample_weight.copy())\n",
    "\n",
    "    # цикл по длине М\n",
    "    for m in range(M):   \n",
    "\n",
    "        # обучим базовую модель и получим предсказание\n",
    "        estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2)\n",
    "        estimator.fit(X, y, sample_weight=sample_weight)\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        # Маска для ошибок классификации\n",
    "        incorrect = (y_predict != y)\n",
    "\n",
    "        # Оцениваем ошибку\n",
    "        estimator_error = sample_weight[incorrect].sum() \n",
    "        \n",
    "        # Вычисляем вес нового алгоритма\n",
    "        estimator_weight =  learning_rate*np.log((1-estimator_error)/estimator_error)\n",
    "\n",
    "        # Получаем новые веса объектов\n",
    "        sample_weight *= np.exp(estimator_weight*incorrect*((sample_weight > 0) | (estimator_weight < 0)))\n",
    "\n",
    "        # Сохраяем результаты данной итерации\n",
    "        estimator_list.append(estimator)\n",
    "        y_predict_list.append(y_predict.copy())\n",
    "        estimator_error_list.append(estimator_error.copy())\n",
    "        estimator_weight_list.append(estimator_weight.copy())\n",
    "        sample_weight_list.append(sample_weight.copy())\n",
    "        \n",
    "\n",
    "\n",
    "    # Для удобства переведем в numpy.array   \n",
    "    estimator_list = np.asarray(estimator_list)\n",
    "    y_predict_list = np.asarray(y_predict_list)\n",
    "    estimator_error_list = np.asarray(estimator_error_list)\n",
    "    estimator_weight_list = np.asarray(estimator_weight_list)\n",
    "    sample_weight_list = np.asarray(sample_weight_list)\n",
    "\n",
    "    # Получим предсказания\n",
    "    preds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\n",
    "    print('Accuracy = ', (preds == y).sum() / N) \n",
    "    \n",
    "    return estimator_list, estimator_weight_list, sample_weight_list\n",
    "\n",
    "estimator_list, estimator_weight_list, sample_weight_list  = AdaBoost_scratch(X, y, M=10, learning_rate=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
