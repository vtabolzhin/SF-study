{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVGEqntXHZeD"
   },
   "source": [
    "# 6.2 Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IREftSDTHZeE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1J0r6DYGHZeH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz', sep=',', header=None)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "i7SUi2FRHZeJ",
    "outputId": "a43c76fc-351d-422d-8835-8ef82350b647"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2845</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>201</td>\n",
       "      <td>86</td>\n",
       "      <td>1507</td>\n",
       "      <td>238</td>\n",
       "      <td>212</td>\n",
       "      <td>101</td>\n",
       "      <td>1451</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2828</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>68</td>\n",
       "      <td>1556</td>\n",
       "      <td>239</td>\n",
       "      <td>203</td>\n",
       "      <td>89</td>\n",
       "      <td>1460</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3245</td>\n",
       "      <td>309</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>57</td>\n",
       "      <td>150</td>\n",
       "      <td>173</td>\n",
       "      <td>227</td>\n",
       "      <td>194</td>\n",
       "      <td>1557</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3245</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>335</td>\n",
       "      <td>46</td>\n",
       "      <td>430</td>\n",
       "      <td>218</td>\n",
       "      <td>214</td>\n",
       "      <td>131</td>\n",
       "      <td>1298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3098</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>467</td>\n",
       "      <td>174</td>\n",
       "      <td>2294</td>\n",
       "      <td>214</td>\n",
       "      <td>187</td>\n",
       "      <td>99</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "9995  2845   77  15  201   86  1507  238  212  101  1451  ...   0   1   0   0   \n",
       "9996  2828   74  18  150   68  1556  239  203   89  1460  ...   0   1   0   0   \n",
       "9997  3245  309  16  150   57   150  173  227  194  1557  ...   0   0   0   0   \n",
       "9998  3245   33  12  335   46   430  218  214  131  1298  ...   0   0   0   0   \n",
       "9999  3098   37  22  467  174  2294  214  187   99  2290  ...   0   1   0   0   \n",
       "\n",
       "      49  50  51  52  53  54  \n",
       "9995   0   0   0   0   0   5  \n",
       "9996   0   0   0   0   0   5  \n",
       "9997   0   0   0   0   0   1  \n",
       "9998   0   0   0   0   0   1  \n",
       "9999   0   0   0   0   0   1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Pjzuwk_aHZeM",
    "outputId": "f5b06513-e119-4705-b6ba-1570c36569c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lYKjBKSsHZeO"
   },
   "outputs": [],
   "source": [
    "features = list(range(0, 54))\n",
    "target = 54\n",
    "\n",
    "# для упрощения, будем рассотривать только 2 класса, т.е. сделаем задачу бинарной классификации\n",
    "df = df[(df[target] == 1) | (df[target] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2837, 55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "muwO4M4sHZeQ"
   },
   "outputs": [],
   "source": [
    "cover_train, cover_test = train_test_split(df, test_size=0.5)\n",
    "\n",
    "cover_X_train, cover_y_train = cover_train[features], cover_train[target]\n",
    "cover_X_test, cover_y_test = cover_test[features], cover_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "97GG-s4cHZeS"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "cover_X_train = scaler.fit_transform(cover_X_train)\n",
    "cover_X_test = scaler.transform(cover_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRnSXWqzKh3x"
   },
   "source": [
    "Stacking — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle.  \n",
    "Подход использует понятие _базовых классификаторов_, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также _мета-классификатора_, использующего предсказания базовых классификаторов как признаки.\n",
    "\n",
    "Для избежания переобучения будем разбивать обучающую выборку на фолды.  \n",
    "Например, фолды при разбиении на три части:  \n",
    "``==*``  \n",
    "``=*=``  \n",
    "``*==``  \n",
    "\n",
    "Это требуется для того, чтобы получить новые признаки (ответы алгоритмов на первом уровне) на всей обучающей выборке, т.е. ответы алгоритма на тех объектах, которые не были использованы во время обучения. В примере выше мы будем использовать ответы алгоритма, полученные на объектах звездочках. _Важно_: на каждом фолде мы обучаем алгоритм заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hcomzpKcHZeU"
   },
   "outputs": [],
   "source": [
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Computes meta-features using the classifier.\n",
    "    \n",
    "    :arg clf: scikit-learn classifier\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "        \n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n",
    "    \n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IcKj44HrHZeW"
   },
   "outputs": [],
   "source": [
    "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Generates metafeatures using a list of classifiers.\n",
    "    \n",
    "    :arg classifiers: list of scikit-learn classifiers\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "        for clf in tqdm(classifiers)\n",
    "    ]\n",
    "    \n",
    "    stacked_features_train = np.vstack([\n",
    "        features_train for features_train, features_test in features\n",
    "    ]).T\n",
    "\n",
    "    stacked_features_test = np.vstack([\n",
    "        features_test for features_train, features_test in features\n",
    "    ]).T\n",
    "    \n",
    "    return stacked_features_train, stacked_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4V6xy7_0HZeY"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Gbv7YXs8HZea",
    "outputId": "35cd300d-f3f9-4055-9967-3dc70b434e51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885835095137421"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=300)\n",
    "clf.fit(cover_X_train, cover_y_train)\n",
    "\n",
    "accuracy_score(clf.predict(cover_X_test), cover_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NmrhIV1aHZec",
    "outputId": "b9817055-7d57-46bd-f66e-8f0bff9c42b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "stacked_features_train, stacked_features_test = generate_meta_features([\n",
    "    LogisticRegression(C=0.001, penalty='l1', solver='liblinear', max_iter=5000),\n",
    "    LogisticRegression(C=0.001, penalty='l2', solver='liblinear', max_iter=5000),  \n",
    "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
    "    GradientBoostingClassifier(n_estimators=300)\n",
    "], cover_X_train, cover_X_test, cover_y_train.values, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KAqWN10ZHZee"
   },
   "outputs": [],
   "source": [
    "total_features_train = np.hstack([cover_X_train, stacked_features_train])\n",
    "total_features_test = np.hstack([cover_X_test, stacked_features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B-wCuCCdHZef",
    "outputId": "1a3137a3-815b-47ea-9fa1-639d4b2bebc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062015503875969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
    "clf.fit(stacked_features_train, cover_y_train)\n",
    "accuracy_score(clf.predict(stacked_features_test), cover_y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m6.5_Практика.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
